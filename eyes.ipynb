{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FlAthexlmMxx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.MobileNetV2()\n"
      ],
      "metadata": {
        "id": "3SsubjTWFKm-"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/content/drive/MyDrive/strabismus cnn model/testing'\n",
        "train_dir = '/content/drive/MyDrive/strabismus cnn model/training '"
      ],
      "metadata": {
        "id": "anKrveAinaXE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 160, 160\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "GPB0W8l5piDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f890fe10-8f2a-444b-8c8c-62eec5162279"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 279 images belonging to 2 classes.\n",
            "Found 289 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(img_width, img_height, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "id": "7ZySJ1PewWz_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "gMvIUX7_wbp7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(train_generator.num_classes, activation='sigmoid')\n",
        "layer = tf.keras.layers.Dense(128, activation='relu')\n",
        "layer2 = tf.keras.layers.Dense(64, activation='relu')\n",
        "layer3 = tf.keras.layers.Dense(32, activation='relu')\n",
        "layer4 = tf.keras.layers.Dense(16, activation='relu')\n",
        "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
        "dropout_layer2 = tf.keras.layers.Dropout(0.25)\n",
        "dropout_layer3 = tf.keras.layers.Dropout(0.125)"
      ],
      "metadata": {
        "id": "YBouBOW5whEp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    global_average_layer,\n",
        "    layer,\n",
        "    dropout_layer3,\n",
        "\n",
        "    prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "dLKz00mwwlZ_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6_zszAfVwpNs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=8,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47wJIMmqwsdc",
        "outputId": "ece3f8a2-8545-44fd-8b0f-9b905428c065"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "9/9 [==============================] - 24s 2s/step - loss: 0.1254 - accuracy: 0.9498 - val_loss: 0.5737 - val_accuracy: 0.8097\n",
            "Epoch 2/8\n",
            "9/9 [==============================] - 16s 2s/step - loss: 0.1022 - accuracy: 0.9677 - val_loss: 0.6563 - val_accuracy: 0.7855\n",
            "Epoch 3/8\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0838 - accuracy: 0.9749 - val_loss: 0.5933 - val_accuracy: 0.8131\n",
            "Epoch 4/8\n",
            "9/9 [==============================] - 20s 2s/step - loss: 0.0832 - accuracy: 0.9713 - val_loss: 0.6903 - val_accuracy: 0.7958\n",
            "Epoch 5/8\n",
            "9/9 [==============================] - 17s 2s/step - loss: 0.0735 - accuracy: 0.9785 - val_loss: 0.6206 - val_accuracy: 0.8062\n",
            "Epoch 6/8\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.0648 - accuracy: 0.9785 - val_loss: 0.6457 - val_accuracy: 0.8028\n",
            "Epoch 7/8\n",
            "9/9 [==============================] - 18s 2s/step - loss: 0.0788 - accuracy: 0.9713 - val_loss: 0.6081 - val_accuracy: 0.8166\n",
            "Epoch 8/8\n",
            "9/9 [==============================] - 14s 2s/step - loss: 0.0656 - accuracy: 0.9928 - val_loss: 0.7483 - val_accuracy: 0.7855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_path = input('Enter the path of the image: ')\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_width, img_height))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions)\n",
        "\n",
        "class_names = train_generator.class_indices\n",
        "class_name = list(class_names.keys())[list(class_names.values()).index(predicted_class)]\n",
        "\n",
        "print(f'The image belongs to class: {class_name}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSguGUkLwvO-",
        "outputId": "f0261b83-a936-4bbb-b01a-aff714af3d05"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path of the image: /content/drive/MyDrive/strabismus cnn model/testing/normal eyes/Advantages-of-having-Two-Eyes-1.png\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "The image belongs to class: normal eyes\n"
          ]
        }
      ]
    }
  ]
}